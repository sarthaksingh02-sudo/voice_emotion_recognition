"""
Optimized test script to validate speed and accuracy improvements
"""
import time
import numpy as np
from pathlib import Path

from audio_processor import AudioProcessor  
from model_trainer import EmotionModelTrainer
from config import *

def test_optimized_pipeline():
    """Test the optimized pipeline"""
    print("ğŸš€ Testing Optimized Voice Emotion Recognition Pipeline")
    print("=" * 60)
    
    # Configuration info
    print(f"ğŸ“‹ Current Configuration:")
    print(f"  - Sample Rate: {SAMPLE_RATE} Hz")
    print(f"  - Pitch Features: {'âœ… Enabled' if ENABLE_PITCH_FEATURES else 'âŒ Disabled'}")
    print(f"  - Mel Features: {'âœ… Enabled' if ENABLE_MEL_FEATURES else 'âŒ Disabled'}")
    print(f"  - Parallel Processing: {'âœ… Enabled' if USE_PARALLEL_PROCESSING else 'âŒ Disabled'}")
    print(f"  - Caching: {'âœ… Enabled' if CACHE_FEATURES else 'âŒ Disabled'}")
    print(f"  - Max Workers: {MAX_WORKERS}")
    print()
    
    # Initialize trainer
    trainer = EmotionModelTrainer()
    data_dir = Path("data")
    
    if not data_dir.exists():
        print(f"âŒ Data directory not found: {data_dir}")
        return False
    
    # Run the complete optimized pipeline
    print("ğŸ¯ Running complete optimized pipeline...")
    start_time = time.time()
    
    try:
        best_model, best_score = trainer.train_complete_pipeline(data_dir)
        
        total_time = time.time() - start_time
        
        if best_model is not None:
            print(f"\nğŸ‰ Pipeline completed successfully!")
            print(f"â±ï¸ Total time: {total_time:.2f} seconds ({total_time/60:.1f} minutes)")
            print(f"ğŸ† Best model accuracy: {best_score:.4f} ({best_score*100:.1f}%)")
            print(f"ğŸ¤– Best model: {trainer.best_model_name}")
            
            # Calculate performance metrics
            stats = trainer.audio_processor.get_processing_stats()
            if stats['total_processed'] > 0:
                success_rate = (stats['feature_extraction_success'] / stats['total_processed']) * 100
                avg_time_per_file = total_time / stats['total_processed']
                print(f"ğŸ“Š Feature extraction success rate: {success_rate:.1f}%")
                print(f"âš¡ Average time per file: {avg_time_per_file:.3f} seconds")
                
                # Check if we hit our targets
                print(f"\nğŸ¯ Target Achievement:")
                if success_rate >= 90:
                    print(f"  âœ… Success rate target (90%+): {success_rate:.1f}%")
                else:
                    print(f"  âŒ Success rate target (90%+): {success_rate:.1f}%")
                
                if avg_time_per_file <= 0.2:
                    print(f"  âœ… Speed target (â‰¤0.2s): {avg_time_per_file:.3f}s")
                else:
                    print(f"  âŒ Speed target (â‰¤0.2s): {avg_time_per_file:.3f}s")
                
                if best_score >= 0.85:
                    print(f"  âœ… Accuracy target (â‰¥85%): {best_score*100:.1f}%")
                else:
                    print(f"  âŒ Accuracy target (â‰¥85%): {best_score*100:.1f}%")
            
            return True
        else:
            print("âŒ Pipeline failed - no model trained")
            return False
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Training interrupted by user")
        return False
    except Exception as e:
        print(f"âŒ Pipeline failed with error: {e}")
        return False

if __name__ == "__main__":
    success = test_optimized_pipeline()
    
    if success:
        print("\nğŸ‰ Optimization test completed successfully!")
        print("ğŸš€ Ready for GitHub push!")
    else:
        print("\nâŒ Optimization test failed.")
        print("ğŸ”§ Check the errors above and try again.")
